---
layout: post
title: "[ML] Train and deploy AI models at trillion-parameter scale with Amazon SageMaker HyperPod support for P6e-GB200 UltraServers"
date: 2025-08-12T19:57:57.000+00:00
categories: [aws, ai-ml]
tags: [Amazon SageMaker HyperPod, NVIDIA]
toc: true
math: false
author: "AWS Blog 摘要"
original_author: "Nathan Arnold"
original_link: "https://aws.amazon.com/blogs/machine-learning/train-and-deploy-ai-models-at-trillion-parameter-scale-with-amazon-sagemaker-hyperpod-support-for-p6e-gb200-ultraservers/"
---

# 🤖 Train and deploy AI models at trillion-parameter scale with Amazon SageMaker HyperPod support for P6e-GB200 UltraServers

> **原文链接**: [Train and deploy AI models at trillion-parameter scale with Amazon SageMaker HyperPod support for P6e-GB200 UltraServers](https://aws.amazon.com/blogs/machine-learning/train-and-deploy-ai-models-at-trillion-parameter-scale-with-amazon-sagemaker-hyperpod-support-for-p6e-gb200-ultraservers/)
> **作者**: Nathan Arnold
> **发布日期**: 2025-08-12 19:57:57 UTC

## 📋 内容摘要

本文介绍了Amazon SageMaker HyperPod新推出的P6e-GB200 UltraServers支持。这项创新技术配备72个NVIDIA Blackwell GPU，可提供360 petaflops的FP8计算能力和1.4 exaflops的FP4稀疏计算能力。UltraServers具有两种规格：ml.u-p6e-gb200x36（36个GPU）和ml.u-p6e-gb200x72（72个GPU）。系统特点包括：超高GPU算力、130 TBps的NVLink带宽、405 TB本地NVMe SSD存储、优化的网络拓扑和调度功能。该系统特别适合训练和部署万亿参数级AI模型，支持实时推理，并能显著提升大语言模型和混合专家模型的性能。目前通过灵活训练计划在达拉斯AWS本地区域提供服务，可与SageMaker HyperPod和训练任务无缝集成，为企业AI开发提供高效、可扩展的解决方案。

## 🔗 相关信息

这是来自 AWS 官方博客的最新资讯摘要。点击上方原文链接查看完整内容和技术细节。

### 🏷️ 涉及的 AWS 服务和主题

- **Amazon SageMaker HyperPod**
- **NVIDIA**

## 📚 延伸阅读

- [AWS 官方文档](https://docs.aws.amazon.com/)
- [AWS 架构中心](https://aws.amazon.com/architecture/)
- [AWS 最佳实践](https://aws.amazon.com/architecture/well-architected/)

---

*本文为 AWS 官方博客内容摘要，完整内容请访问原文链接。版权归原作者所有。*