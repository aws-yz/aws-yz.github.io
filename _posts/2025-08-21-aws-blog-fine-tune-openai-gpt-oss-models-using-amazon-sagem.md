---
layout: post
title: "[ML] Fine-tune OpenAI GPT-OSS models using Amazon SageMaker HyperPod recipes"
date: 2025-08-21T21:35:59.000+00:00
categories: [aws, ai-ml, news]
tags: [Amazon SageMaker, Amazon SageMaker AI, Announcements, Artificial Intelligence, Foundation models]
toc: true
math: false
author: "AWS Blog 摘要"
original_author: "Durga Sury"
original_link: "https://aws.amazon.com/blogs/machine-learning/fine-tune-openai-gpt-oss-models-using-amazon-sagemaker-hyperpod-recipes/"
---

# 🤖 Fine-tune OpenAI GPT-OSS models using Amazon SageMaker HyperPod recipes

> **原文链接**: [Fine-tune OpenAI GPT-OSS models using Amazon SageMaker HyperPod recipes](https://aws.amazon.com/blogs/machine-learning/fine-tune-openai-gpt-oss-models-using-amazon-sagemaker-hyperpod-recipes/)
> **作者**: Durga Sury
> **发布日期**: 2025-08-21 21:35:59 UTC

## 📋 内容摘要

本文是GPT-OSS系列的第二部分，重点介绍如何使用Amazon SageMaker HyperPod recipes来微调OpenAI的GPT-OSS模型。文章详细说明了如何通过SageMaker HyperPod或训练作业来微调GPT-OSS模型，包括使用多语言推理数据集进行训练。文章还介绍了如何使用vLLM框架将微调后的模型部署到SageMaker端点进行推理。主要内容包括环境设置、数据准备、模型训练配置、部署过程以及清理资源等步骤。这个端到端的工作流程帮助组织在使用AWS可扩展基础设施和SageMaker全面ML平台功能的同时构建和服务定制的LLM解决方案。

## 🔗 相关信息

这是来自 AWS 官方博客的最新资讯摘要。点击上方原文链接查看完整内容和技术细节。

### 🏷️ 涉及的 AWS 服务和主题

- **Amazon SageMaker**
- **Amazon SageMaker AI**
- **Announcements**
- **Artificial Intelligence**
- **Foundation models**

## 📚 延伸阅读

- [AWS 官方文档](https://docs.aws.amazon.com/)
- [AWS 架构中心](https://aws.amazon.com/architecture/)
- [AWS 最佳实践](https://aws.amazon.com/architecture/well-architected/)

---

*本文为 AWS 官方博客内容摘要，完整内容请访问原文链接。版权归原作者所有。*